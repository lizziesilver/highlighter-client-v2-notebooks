{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSXtPck7qONj"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "-f https://download.pytorch.org/whl/torch_stable.html\n",
        "torch==1.8.0+cu111\n",
        "torchvision==0.9.0+cu111\n",
        "\n",
        "\n",
        "-i https://<PYPI_USERNAME>:<PYPI_PASSWORD>@pypi.silverpond.com.au/simple\n",
        "highlighter-client-v2-alpha==0.2\n",
        "\n",
        "--extra-index-url https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html\n",
        "mmcv-full==1.3.17+torch1.8.0+cu111\n",
        "\n",
        "onnx\n",
        "onnxruntime==1.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWkYiA4ydTJl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!!apt-get install libmagic-dev\n",
        "!git clone --depth 1 --branch v2.18.0 https://github.com/open-mmlab/mmdetection.git\n",
        "!pip install -r requirements.txt\n",
        "!(cd mmdetection; pip install .)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9jw3uSeP3H"
      },
      "source": [
        "# House Keeping"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0UUUeuy_mMb"
      },
      "outputs": [],
      "source": [
        "from highlighter_client.gql_client import HLClient\n",
        "\n",
        "# Needed when using HighlighterClient in a notebook environment\n",
        "HLClient._async = True\n",
        "\n",
        "# Small helper function for displaying the DataFrames in the highlighter clinet\n",
        "# dataset object\n",
        "def display_ds(ds, count=10):\n",
        "    display(ds.annotations_df.head(count))\n",
        "    display(ds.images_df.head(count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5xgoT06YVuG"
      },
      "source": [
        "# Download data using Highlighter Client.\n",
        "\n",
        "For a more detailed run through of how to use HighlighterClient see the [export-submissions](https://github.com/tall-josh/highlighter-client-v2-notebooks/blob/main/export-submissions.ipynb) notebook.\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_jUmZFgYUD3"
      },
      "outputs": [],
      "source": [
        "HL_WEB_GRAPHQL_API_TOKEN=\"...\"\n",
        "HL_WEB_GRAPHQL_ENDPOINT=\"https://<account-name>.highlighter.ai/graphql\"\n",
        "\n",
        "dataset_id = 191"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_jUmZFgYUD3"
      },
      "outputs": [],
      "source": [
        "from highlighter_client.datasets import get_reader, get_writer\n",
        "from highlighter_client.datasets.dataset import Dataset\n",
        "from highlighter_client.base_models import DatasetSubmissionTypeConnection\n",
        "from highlighter_client.paginate import paginate\n",
        "\n",
        "ds = Dataset(\n",
        "    reader=get_reader(\"highlighter_submissions\")(),\n",
        "    writer=get_writer(\"coco\")(),\n",
        ")\n",
        "\n",
        "client = HLClient.from_credential(api_token=HL_WEB_GRAPHQL_API_TOKEN, endpoint_url=HL_WEB_GRAPHQL_ENDPOINT)\n",
        "\n",
        "submissions_gen = paginate(\n",
        "client.datasetSubmissionConnection,\n",
        "DatasetSubmissionTypeConnection,\n",
        "datasetId=dataset_id,\n",
        ")\n",
        "\n",
        "print(\"This could take a minute\")\n",
        "ds.read(submissions_gen=submissions_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q1bTTxbzDQL"
      },
      "outputs": [],
      "source": [
        "display_ds(ds)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing\n",
        "\n",
        "At this point you may wish to do some pre-processing eg:\n",
        "\n",
        "  - **remove unwanted classes**: You may wish to filter some annotations from your dataset\n",
        "  - **split the data**: notice the `split` column is only a single value *data*. We can apply a random split before saving to `coco` format.\n",
        "\n",
        "To keep things general we will simply split the data into **train** and **test** in this notebook\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_frac = 0.8\n",
        "ds.images_df[\"split\"] = \"train\"\n",
        "\n",
        "test_ids = ds.images_df.sample(frac=1-train_frac, random_state=42).image_id\n",
        "ds.images_df.loc[ds.images_df.image_id.isin(test_ids), \"split\"] = \"test\"\n",
        "ds.images_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "image_dir = Path(\"data/images\")\n",
        "annotations_dir = Path(\"data/annotatoins\")\n",
        "\n",
        "image_dir.mkdir(parents=True, exist_ok=True)\n",
        "annotations_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ds.write(annotations_dir=annotations_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check the json files exported correctly\n",
        "\n",
        "We'll also get the number of categories in the training data. We will need it\n",
        "when we configure the mmdet model for training.\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with (annotations_dir/\"train.json\").open('r') as f:\n",
        "    train_data = json.load(f)\n",
        "    \n",
        "# We'll use this later when configuring the mmdet frcnn model\n",
        "categories = train_data[\"categories\"]\n",
        "sorted(categories, key = lambda i: i[\"id\"])\n",
        "\n",
        "num_classes = len(categories)\n",
        "\n",
        "for c in categories:\n",
        "    print(c)\n",
        "    \n",
        "CLASSES = [i[\"name\"] for i in categories]\n",
        "\n",
        "print(f\"num_images: {len(train_data['images'])}\")\n",
        "print(f\"num_annos: {len(train_data['annotations'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from highlighter_client.io import multithread_graphql_image_download\n",
        "\n",
        "HLClient._async = False\n",
        "result = multithread_graphql_image_download(\n",
        "    client,\n",
        "    list(ds.images_df.image_id.values),\n",
        "    image_dir,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "\n",
        "mmdet_config = dict(\n",
        "    work_dir = \"zzz_work_dir\",\n",
        "    gpu_ids = [0],\n",
        "    seed = 42,\n",
        "    data = dict(\n",
        "        train = dict(\n",
        "            ann_file=str(annotations_dir / \"train.json\"),\n",
        "            img_prefix=str(image_dir),\n",
        "        ),\n",
        "        val = dict(\n",
        "            ann_file=str(annotations_dir / \"test.json\"),\n",
        "            img_prefix=str(image_dir),\n",
        "        ),\n",
        "        test = dict(\n",
        "            ann_file=str(annotations_dir / \"test.json\"),\n",
        "            img_prefix=str(image_dir),\n",
        "        ),\n",
        "    ),\n",
        "    model = dict(\n",
        "        roi_head = dict(\n",
        "            bbox_head = dict(\n",
        "                num_classes = num_classes,\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "cfg = Config.fromfile(\"mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py\")\n",
        "cfg.merge_from_dict(mmdet_config)\n",
        "cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg.data.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "import mmcv\n",
        "import os.path as osp\n",
        "\n",
        "\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "datasets[0].CLASSES = CLASSES\n",
        "\n",
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir(Config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_mmdetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}